{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Fti0weu54sfC"
      },
      "outputs": [],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "sJP9K4aqTscA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Kh24FDn653UT"
      },
      "source": [
        " # Collection of library and modules that are going to be used throughout the project\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xxlZ8HRk-IUs"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import os\n",
        "import sklearn\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import numpy as np, pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.model_selection import train_test_split,cross_val_score,KFold,GridSearchCV\n",
        "from sklearn.linear_model import Ridge\n",
        "from sklearn.metrics import mean_squared_error, r2_score, mean_absolute_error\n",
        "from sklearn.linear_model import LinearRegression\n",
        "from sklearn.ensemble import RandomForestRegressor\n",
        "from sklearn.tree import DecisionTreeRegressor\n",
        "from sklearn.ensemble import RandomForestRegressor,GradientBoostingRegressor,StackingRegressor,BaggingRegressor, VotingRegressor\n",
        "from sklearn.svm import SVR, NuSVR\n",
        "from sklearn.pipeline import Pipeline\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iwzdn2UU5_n8"
      },
      "source": [
        "# Reading of the dataset from the training of various models\n",
        "\n",
        "* -- identifying columns and datatypes\n",
        "\n",
        "* -- removes some of the columns based on their insignificance to our model dependent variable\n",
        "\n",
        "* -- Identify categorical and numerical data and encode them if necessary\n",
        "\n",
        "* -- Scaling of data to avoid biases"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BPTORAjd9pa7"
      },
      "outputs": [],
      "source": [
        "tdata = pd.read_csv('drive/MyDrive/IntroAi/players_21.csv')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "e_qwJA9kCXlq"
      },
      "outputs": [],
      "source": [
        "# checking the number of colums and their datatypes\n",
        "tdata.info()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Kmpigm4uCbri"
      },
      "outputs": [],
      "source": [
        "tdata.columns\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "f-w3sKKsErGP"
      },
      "outputs": [],
      "source": [
        "#checking our target variable and see if there is some missing values\n",
        "tdata['overall']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OtxedFADbV-l"
      },
      "outputs": [],
      "source": [
        "# copy the dataset into a new variable to ensure that if we make some changes we can still go back to the original dataset\n",
        "newdata = tdata.copy()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LR2kCW5DfIk_"
      },
      "outputs": [],
      "source": [
        "newdata.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-wOBER9k62iD"
      },
      "source": [
        "# Cleaning of the data\n",
        "\n",
        "* Dropping all columns with more than 30% Nan\n",
        "* Drop other non numerical columns that by definition of the dataset will not contribute to our dependent variable"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VL1iGKnocu-X"
      },
      "outputs": [],
      "source": [
        "# Finding of the percentage of missing value in each column\n",
        "nan_percent = (newdata.isna().sum()/len(newdata))*100"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nkL5kX__dn8W"
      },
      "outputs": [],
      "source": [
        "# Dropping of the same of the columns with >= 30% NaN\n",
        "columns_to_drop = nan_percent[nan_percent>=30].index"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7r_J0UCjd0mn"
      },
      "outputs": [],
      "source": [
        "# Checking the columns identified\n",
        "columns_to_drop"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pjU6IaS1d3Rb"
      },
      "outputs": [],
      "source": [
        "# Dropping of the columns identified above\n",
        "newdata = newdata.drop(columns = columns_to_drop, axis = 1)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hRerFb0W6_1x"
      },
      "source": [
        "# Separation of numerical and categorical data\n",
        "\n",
        "* identify the categorical and put them in one subset dataframe\n",
        "* identify the numerical data and put them in one subset dataframe\n",
        "* encode the categorical data to make them numeric\n",
        "* Concatinate the the two dataset to form the final dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PSE74hZOlB1X"
      },
      "outputs": [],
      "source": [
        "# numerical data\n",
        "numedata = newdata.select_dtypes(exclude=['object'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VUCmyQMnEIbC"
      },
      "outputs": [],
      "source": [
        "# categical data\n",
        "catedata = newdata.select_dtypes(include =['object'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uFv1FlUdmwCy"
      },
      "outputs": [],
      "source": [
        "# Inspecting the numerical data\n",
        "numedata.info()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XS5S2GD7nG7K"
      },
      "outputs": [],
      "source": [
        "# inspecting the categorical data\n",
        "catedata.info()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FO3CM5T07WQ3"
      },
      "source": [
        "transformation of categorical data into numerical data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wwX60c3ggGfK"
      },
      "outputs": [],
      "source": [
        "columns = catedata.columns"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CCEy2gDxv71y"
      },
      "outputs": [],
      "source": [
        "columns"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# filling numerical missing value with mean\n",
        "numedata = numedata.fillna(numedata.mean())"
      ],
      "metadata": {
        "id": "UVfZjtdESP9a"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_37kpMc7uAvX"
      },
      "outputs": [],
      "source": [
        "# factorization of the categorical data\n",
        "\n",
        "factoData = pd.DataFrame()\n",
        "for col in columns:\n",
        "    factoData[col] = pd.factorize(catedata[col])[0]\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iTzzvE0nCFbO"
      },
      "outputs": [],
      "source": [
        "# concatenation of the categorical and numerical data\n",
        "data = pd.concat([numedata,factoData], axis =1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3mFJ13sviHA6"
      },
      "outputs": [],
      "source": [
        "data = data.fillna(data.mean())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YJKEwpEMiPiF"
      },
      "outputs": [],
      "source": [
        "data = data.drop([\"player_url\", \"short_name\",\"long_name\", \"player_face_url\"], axis = 1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cb4-bd1iCn5a"
      },
      "outputs": [],
      "source": [
        "y= data[\"overall\"]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "22QtOjwYC1L5"
      },
      "outputs": [],
      "source": [
        "x = data.drop([\"overall\"], axis = 1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7Ci6_nnjg95U"
      },
      "outputs": [],
      "source": [
        "from sklearn.preprocessing import StandardScaler\n",
        "scaled = StandardScaler()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rOzZL8LzhDIX"
      },
      "outputs": [],
      "source": [
        "scaleddata = scaled.fit_transform(x)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NQVCqGp6hJ9N"
      },
      "outputs": [],
      "source": [
        "x = pd.DataFrame(scaleddata, columns = x.columns)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RRbb43dji8uS"
      },
      "outputs": [],
      "source": [
        "x.info()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "w-GC0QW4QB12"
      },
      "source": [
        "#Different Regression model to use for feature importances"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pmATXgr7QYFp"
      },
      "source": [
        "1st model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gRmwnDN29gJi"
      },
      "outputs": [],
      "source": [
        "randommodel = RandomForestRegressor(n_estimators=150, random_state=42)\n",
        "randommodel.fit(x,y)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "G3_tL9GAhcOJ"
      },
      "outputs": [],
      "source": [
        "feature_importances = randommodel.feature_importances_\n",
        "\n",
        "# Create a DataFrame to display feature names and their importances\n",
        "feature_importance_df = pd.DataFrame({'Feature': x.columns, 'Importance': feature_importances})\n",
        "\n",
        "# Sort features by importance in descending order\n",
        "feature_importance_df = feature_importance_df.sort_values(by='Importance', ascending=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "e6g8pKVmjrl-"
      },
      "outputs": [],
      "source": [
        "# looking at the best 10 columns that contribute highly on the predicted model\n",
        "feature_importance_df[0:10]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rUn8oeZNp8Bx"
      },
      "source": [
        "2nd model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EaO1b85Mpw7F"
      },
      "outputs": [],
      "source": [
        "tree = DecisionTreeRegressor()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bQTxyrY8qB0E"
      },
      "outputs": [],
      "source": [
        "tree.fit(x,y)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kjfy_1nZlWmK"
      },
      "outputs": [],
      "source": [
        "feature_importances = tree.feature_importances_\n",
        "\n",
        "# Create a DataFrame to display feature names and their importances\n",
        "feature_importance = pd.DataFrame({'Feature': x.columns, 'Importance': feature_importances})\n",
        "\n",
        "# Sort features by importance in descending order\n",
        "feature_importance = feature_importance.sort_values(by='Importance', ascending=False)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wWLri7nXlhvj"
      },
      "outputs": [],
      "source": [
        "feature_importance[0:10]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "anaSGrBNwbsq"
      },
      "source": [
        "#Ensemble learning with the best five columns of the the dataset\n",
        "\n",
        "* Training of at least 3 models\n",
        "* Fine tune them"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vp8hhl3kwVzC"
      },
      "outputs": [],
      "source": [
        "columns = [\"value_eur\",\"release_clause_eur\", \"age\" ,\"potential\" ,\"movement_reactions\", \"overall\"]"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "* dataset that we are going to use for the model training"
      ],
      "metadata": {
        "id": "PlQvpFAeVDsq"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2nzMcq7b0vqY"
      },
      "outputs": [],
      "source": [
        "finaldata = data[columns]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ab_ZVE-o01Zw"
      },
      "outputs": [],
      "source": [
        "finaldata.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "* Splitting of data into dependent and independent variables"
      ],
      "metadata": {
        "id": "6vanXaIkU2OI"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "m0FkyCmv0-rj"
      },
      "outputs": [],
      "source": [
        "Yfinal = finaldata[\"overall\"]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_AMipukL1GP9"
      },
      "outputs": [],
      "source": [
        "Xfinal = finaldata.drop([\"overall\"], axis =1)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "* Scaling of independent variables"
      ],
      "metadata": {
        "id": "AuJC2GcgUxXa"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dnzfIT871LvJ"
      },
      "outputs": [],
      "source": [
        "# scaling of Xfinal data\n",
        "\n",
        "scal = StandardScaler()\n",
        "scaledfinal = scal.fit_transform(Xfinal)\n",
        "\n",
        "Xfinal = pd.DataFrame(scaledfinal, columns = Xfinal.columns)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aQp7-N2L1uZG"
      },
      "source": [
        "* first model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-B5BjZ4I1te5"
      },
      "outputs": [],
      "source": [
        "svr_model = SVR(kernel = \"rbf\")\n",
        "svr_model.fit(Xfinal,Yfinal)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "* Second  model"
      ],
      "metadata": {
        "id": "UTEvJrY7VN6M"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gx-meI2I2K4Q"
      },
      "outputs": [],
      "source": [
        "tree_model = DecisionTreeRegressor()\n",
        "tree_model.fit(Xfinal, Yfinal)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "* 3rd model"
      ],
      "metadata": {
        "id": "gUsDfdE1Ve3V"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "N1fbnYCU2Z1A"
      },
      "outputs": [],
      "source": [
        "random_model = RandomForestRegressor(n_estimators = 150)\n",
        "random_model.fit(Xfinal,Yfinal)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "* 4th model"
      ],
      "metadata": {
        "id": "M-sob9uFVisA"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Aa50RU4g2tZ4"
      },
      "outputs": [],
      "source": [
        "gradient_model = GradientBoostingRegressor(n_estimators = 1000, learning_rate=0.2)\n",
        "gradient_model.fit(Xfinal,Yfinal)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "* 5th model"
      ],
      "metadata": {
        "id": "4ApaeGKVVtm2"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NPE2kOzG7dBV"
      },
      "outputs": [],
      "source": [
        "nu_model = NuSVR(kernel = \"rbf\", nu = 0.9)\n",
        "\n",
        "nu_model.fit(Xfinal, Yfinal)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "* 6th model"
      ],
      "metadata": {
        "id": "xrWJO2AAVyzM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "base_models = [(\"decision_tree\",DecisionTreeRegressor()),\n",
        "               (\"SVR\", SVR(kernel = \"rbf\")),\n",
        "               (\"random_forest\", RandomForestRegressor(n_estimators = 150, random_state =42)),\n",
        "               ('Gradient_model',GradientBoostingRegressor(n_estimators = 150, learning_rate = 0.1, max_depth =1, random_state =42)),\n",
        "               (\"Nu_svr\", NuSVR(kernel =\"rbf\",nu = 0.5))\n",
        "               ]"
      ],
      "metadata": {
        "id": "zcRj1wprV6_H"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "* 7th model"
      ],
      "metadata": {
        "id": "VSAWKm42WXgJ"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Nwnrq46o9-Ji"
      },
      "outputs": [],
      "source": [
        "stacking_model = StackingRegressor(estimators=base_models, final_estimator= LinearRegression())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "L-Na85P2-XuR"
      },
      "outputs": [],
      "source": [
        "stacking_model.fit(Xfinal,Yfinal)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "* 8th model"
      ],
      "metadata": {
        "id": "em3P0BO7WfFi"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JsVmWwEICDld"
      },
      "outputs": [],
      "source": [
        "voting_model = VotingRegressor(estimators = [(\"decision_tree\",DecisionTreeRegressor()),\n",
        "               (\"SVR\", SVR(kernel = \"rbf\")),\n",
        "               (\"random_forest\", RandomForestRegressor(n_estimators = 150, random_state =42)),\n",
        "               ('Gradient_model',GradientBoostingRegressor(n_estimators = 150, learning_rate = 0.1, max_depth =1, random_state =42)),\n",
        "               ])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "a_BA14NyDXIu"
      },
      "outputs": [],
      "source": [
        "voting_model.fit(Xfinal,Yfinal)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "* 9th model"
      ],
      "metadata": {
        "id": "B0k8x47dWpKl"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "I7fgZM5_D-af"
      },
      "outputs": [],
      "source": [
        "bagging_model = BaggingRegressor(base_estimator = SVR(kernel = \"rbf\"), n_estimators =50, random_state= 42)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dcJsIUIWEfxN"
      },
      "outputs": [],
      "source": [
        "bagging_model.fit(Xfinal,Yfinal)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#cross-validation to find a better parameters for our best model"
      ],
      "metadata": {
        "id": "lHhHV_8mbf9-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "estimators = [\n",
        "    (\"SVR\", SVR(kernel=\"rbf\")),\n",
        "    (\"Gradient_model\", GradientBoostingRegressor())\n",
        "]\n",
        "\n",
        "param_grid = {\n",
        "    'SVR__C': [1, 10, 100],\n",
        "    'Gradient_model__n_estimators': [50, 100, 150],\n",
        "    'Gradient_model__learning_rate': [0.01, 0.1, 0.5]\n",
        "}\n",
        "\n",
        "\n",
        "voting_regressor = VotingRegressor(estimators=estimators)\n",
        "\n",
        "# Perform grid search with cross-validation\n",
        "kfold = KFold(n_splits=5, shuffle=True, random_state=42)\n",
        "grid_search = GridSearchCV(voting_regressor, param_grid, cv=kfold, scoring='neg_mean_squared_error', n_jobs=-1)\n",
        "grid_search.fit(Xfinal, Yfinal)\n",
        "\n",
        "# Print the best hyperparameters and corresponding RMSE score\n",
        "print(\"Best Hyperparameters: \", grid_search.best_params_)\n",
        "print(\"Best RMSE Score: \", np.sqrt(-grid_search.best_score_))"
      ],
      "metadata": {
        "id": "1d6st22zoV5z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "random_seed = 42\n",
        "estimators = [\n",
        "    (\"SVR\", SVR(kernel=\"rbf\")),\n",
        "    (\"Gradient_model\", GradientBoostingRegressor())\n",
        "]\n",
        "\n",
        "param_grid = {\n",
        "    'SVR__C': [1, 10, 100],\n",
        "    'Gradient_model__n_estimators': [50, 100, 150],\n",
        "    'Gradient_model__learning_rate': [0.01, 0.1, 0.5]\n",
        "}\n",
        "\n",
        "voting_regressor = VotingRegressor(estimators=estimators)\n",
        "pipeline = Pipeline([(\"estimators\", voting_regressor)])\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "_STXm_sErYSE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Fit the model and print the results\n",
        "grid_search.fit(Xfinal, Yfinal)\n",
        "best_params = grid_search.best_params_\n",
        "best_score = np.sqrt(-grid_search.best_score_)\n",
        "\n",
        "print(\"Best Hyperparameters:\")\n",
        "for param, value in best_params.items():\n",
        "    print(f\"{param}: {value}\")\n",
        "\n",
        "print(f\"Best RMSE Score: {best_score}\")\n"
      ],
      "metadata": {
        "id": "BISER4ansHgm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Trying the final model with the best paramaters\n",
        "\n"
      ],
      "metadata": {
        "id": "9XfW40x_Noup"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "voting_final = VotingRegressor(estimators=[\n",
        "               (\"SVR\", SVR(kernel='rbf', C=100, gamma=0.1)),\n",
        "               ('Gradient_model',GradientBoostingRegressor(n_estimators = 150, learning_rate = 0.5, max_depth =10, random_state =42)),\n",
        "               ])"
      ],
      "metadata": {
        "id": "9uQiT5ZyNoh9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "voting_final.fit(Xfinal,Yfinal)"
      ],
      "metadata": {
        "id": "nddJ0a7ePx6i"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NMqEu9lut1af"
      },
      "source": [
        "#Time to test our models on unseen data:\n",
        "\n",
        "* clean the testing dataset\n",
        "* Scaling the them\n",
        "* splitting the data into dependent and independent variables\n",
        "* No need for separation of categorical and numerical because we found using feature importance method that all columns that are contributing highly on dependent variable are numeric\n",
        "* Use cross validation to check the best parameters for our ensemble learning models\n",
        "* select the best models based on it MAE and RMSE"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vpCNPsv5ax8G"
      },
      "outputs": [],
      "source": [
        "# importing testing dataset\n",
        "testdata =pd.read_csv('drive/MyDrive/IntroAi/players_22.csv', usecols= columns)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2YnSbWK4uEmF"
      },
      "outputs": [],
      "source": [
        "# inspecting for messing values in each columms\n",
        "testdata.info()"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "* Cleaning and scaling of our testing dataset"
      ],
      "metadata": {
        "id": "OCYmU-eeYKDB"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pz3MB0te2P6o"
      },
      "outputs": [],
      "source": [
        "testdata = testdata.dropna()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Wx1MOqNglzQU"
      },
      "outputs": [],
      "source": [
        "testdata = testdata[columns]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "x0LQPXVa5kzV"
      },
      "outputs": [],
      "source": [
        "testdata.info()"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "* Splitting our dataset into independent and independent variables"
      ],
      "metadata": {
        "id": "2GRcrAcMYVHe"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8lst5BaM2ZRY"
      },
      "outputs": [],
      "source": [
        "Ytestdata = testdata['overall']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Bx8Tq9h22igj"
      },
      "outputs": [],
      "source": [
        "Xtestdata = testdata.drop([\"overall\"], axis =1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FGkR1_DDoIsx"
      },
      "outputs": [],
      "source": [
        "scalerdata = scal.transform(Xtestdata)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "scalerdata"
      ],
      "metadata": {
        "id": "_PfVq_A9MeeZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2XH14nX5oekV"
      },
      "outputs": [],
      "source": [
        "finalxdata = pd.DataFrame(scalerdata, columns =Xtestdata.columns)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1f_XdGkH2vMW"
      },
      "outputs": [],
      "source": [
        "finalxdata.info()"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Model testing on unseen data and checking accuracy"
      ],
      "metadata": {
        "id": "AgZckYpVbFXR"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-Y3EBOi2qHRs"
      },
      "outputs": [],
      "source": [
        "predy1 = tree_model.predict(finalxdata)\n",
        "msetest1 = mean_squared_error(Ytestdata, predy1)\n",
        "r_squaredtest1 = r2_score(Ytestdata, predy1)\n",
        "rmse1 = np.sqrt(msetest1)\n",
        "mae1 = mean_absolute_error(Ytestdata,predy1)\n",
        "print(\"mean absolute Error:\", mae1)\n",
        "print(\"root Squared Error:\", rmse1)\n",
        "print(\"Mean Squared Error:\", msetest1)\n",
        "print(\"root Squared Error:\", rmse1)\n",
        "print(\"R-squared:\", r_squaredtest1)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "M0RIQBhI6CAa"
      },
      "outputs": [],
      "source": [
        "predy2 =random_model.predict(finalxdata)\n",
        "msetest2 = mean_squared_error(Ytestdata, predy2)\n",
        "r_squaredtest2 = r2_score(Ytestdata, predy2)\n",
        "rmse2 = np.sqrt(msetest2)\n",
        "mae2 = mean_absolute_error(Ytestdata,predy2)\n",
        "print(\"mean absolute Error:\", mae2)\n",
        "print(\"root Squared Error:\", rmse2)\n",
        "\n",
        "print(\"Mean Squared Error:\", msetest2)\n",
        "print(\"R-squared:\", r_squaredtest2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "s0fT0h_X6B30"
      },
      "outputs": [],
      "source": [
        "predy3 = svr_model.predict(finalxdata)\n",
        "msetest3 = mean_squared_error(Ytestdata, predy3)\n",
        "r_squaredtest3 = r2_score(Ytestdata, predy3)\n",
        "rmse3 = np.sqrt(msetest3)\n",
        "mae3 = mean_absolute_error(Ytestdata,predy3)\n",
        "print(\"mean absolute Error:\", mae3)\n",
        "print(\"root Squared Error:\", rmse3)\n",
        "print(\"Mean Squared Error:\", msetest3)\n",
        "print(\"R-squared:\", r_squaredtest3)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "70y4DCzP6qmE"
      },
      "outputs": [],
      "source": [
        "predy4 = gradient_model.predict(finalxdata)\n",
        "msetest4 = mean_squared_error(Ytestdata, predy4)\n",
        "r_squaredtest4 = r2_score(Ytestdata, predy4)\n",
        "rmse4 = np.sqrt(msetest4)\n",
        "mae4 = mean_absolute_error(Ytestdata,predy4)\n",
        "print(\"mean absolute Error:\", mae4)\n",
        "print(\"root Squared Error:\", rmse4)\n",
        "\n",
        "print(\"Mean Squared Error:\", msetest4)\n",
        "print(\"R-squared:\", r_squaredtest4)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dHdu5oJB7zHB"
      },
      "outputs": [],
      "source": [
        "predy5 = gradient_model.predict(finalxdata)\n",
        "msetest5 = mean_squared_error(Ytestdata, predy5)\n",
        "r_squaredtest5 = r2_score(Ytestdata, predy5)\n",
        "rmse5 = np.sqrt(msetest5)\n",
        "mae5 = mean_absolute_error(Ytestdata,predy5)\n",
        "print(\"mean absolute Error:\", mae5)\n",
        "print(\"root Squared Error:\", rmse5)\n",
        "\n",
        "print(\"Mean Squared Error:\", msetest5)\n",
        "print(\"R-squared:\", r_squaredtest5)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "D0kDa7lH8XUg"
      },
      "outputs": [],
      "source": [
        "base_models = [(\"decision_tree\",DecisionTreeRegressor()),\n",
        "               (\"SVR\", SVR(kernel = \"rbf\")),\n",
        "               (\"random_forest\", RandomForestRegressor(n_estimators = 150, random_state =42)),\n",
        "               ('Gradient_model',GradientBoostingRegressor(n_estimators = 150, learning_rate = 0.1, max_depth =1, random_state =42)),\n",
        "               (\"Nu_svr\", NuSVR(kernel =\"rbf\",nu = 0.5))\n",
        "               ]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "z0oDzwCOAJmi"
      },
      "source": [
        "# Ensemble learning model testing on unseen data"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "1st ensemble learning model"
      ],
      "metadata": {
        "id": "BLLNl-w0VFbZ"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jsn1vrxf_fz_"
      },
      "outputs": [],
      "source": [
        "predy6 = stacking_model.predict(finalxdata)\n",
        "msetest6 = mean_squared_error(Ytestdata, predy6)\n",
        "r_squaredtest6 = r2_score(Ytestdata, predy6)\n",
        "\n",
        "rmse6 = np.sqrt(msetest6)\n",
        "mae6 = mean_absolute_error(Ytestdata,predy6)\n",
        "print(\"mean absolute Error:\", mae6)\n",
        "print(\"root Squared Error:\", rmse6)\n",
        "\n",
        "print(\"Mean Squared Error:\", msetest6)\n",
        "print(\"R-squared:\", r_squaredtest6)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "2nd ensemble learning model"
      ],
      "metadata": {
        "id": "9sfsqUNBVSDi"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lubtqDOLDszv"
      },
      "outputs": [],
      "source": [
        "\n",
        "predy7 = voting_model.predict(finalxdata)\n",
        "msetest7 = mean_squared_error(Ytestdata, predy7)\n",
        "r_squaredtest7 = r2_score(Ytestdata, predy7)\n",
        "rmse7 = np.sqrt(msetest7)\n",
        "mae7 = mean_absolute_error(Ytestdata,predy7)\n",
        "print(\"mean absolute Error:\", mae7)\n",
        "print(\"root Squared Error:\", rmse7)\n",
        "\n",
        "print(\"Mean Squared Error:\", msetest7)\n",
        "print(\"R-squared:\", r_squaredtest7)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "4th ensemble learning model"
      ],
      "metadata": {
        "id": "fxKd6gQnVX12"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VowTMrmmHEtF"
      },
      "outputs": [],
      "source": [
        "predy8 = bagging_model.predict(finalxdata)\n",
        "msetest8 = mean_squared_error(Ytestdata, predy8)\n",
        "r_squaredtest8 = r2_score(Ytestdata, predy8)\n",
        "rmse8 = np.sqrt(msetest8)\n",
        "mae8 = mean_absolute_error(Ytestdata,predy8)\n",
        "print(\"mean absolute Error:\", mae8)\n",
        "print(\"root Squared Error:\", rmse8)\n",
        "print(\"Mean Squared Error:\", msetest8)\n",
        "print(\"R-squared:\", r_squaredtest8)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Final model that will be deployed.\n",
        "* We used closs validation to find the best paramters"
      ],
      "metadata": {
        "id": "-lD2a3e3Uzm2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "finalPred = voting_final.predict(finalxdata)\n",
        "msetestfinal = mean_squared_error(Ytestdata, finalPred)\n",
        "r_squaredtestfinal = r2_score(Ytestdata,finalPred)\n",
        "rmsefinal = np.sqrt(msetestfinal)\n",
        "maefinal = mean_absolute_error(Ytestdata,finalPred)\n",
        "print(\"mean absolute Error:\", maefinal)\n",
        "print(\"root Squared Error:\", rmsefinal)\n",
        "print(\"Mean Squared Error:\", msetestfinal)\n",
        "print(\"R-squared:\", r_squaredtestfinal)"
      ],
      "metadata": {
        "id": "xO_M8A7PQQ8x"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "columns = finalxdata.columns"
      ],
      "metadata": {
        "id": "DvkHM2ZnWyoF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "columns"
      ],
      "metadata": {
        "id": "vtIylJ3XW3r2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Testing the model on small input"
      ],
      "metadata": {
        "id": "j9gYYKM3S13O"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "voting_final.predict(finalxdata[1000:1050])"
      ],
      "metadata": {
        "id": "Y6RRkJL7RQgx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "Ytestdata[1000:1050]"
      ],
      "metadata": {
        "id": "Z7j2Ku7eRog-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "Xtestdata\n"
      ],
      "metadata": {
        "id": "MSTmXxz5iEbL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "Ytestdata"
      ],
      "metadata": {
        "id": "uTRb3Stn__UZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3Pbq28_7PVNr"
      },
      "source": [
        "# Packaging and downloading the model for development"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_dAbJDi9PSgo"
      },
      "outputs": [],
      "source": [
        "from joblib import dump\n",
        "import joblib"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "dump(scaler,'drive/MyDrive/IntroAi/scaler2.joblib' )"
      ],
      "metadata": {
        "id": "tEJbnI5ARIza"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ujr4IlICPcc6"
      },
      "outputs": [],
      "source": [
        "dump(voting_final, 'drive/MyDrive/IntroAi/voting.joblib')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model = joblib.load('drive/MyDrive/IntroAi/voting.joblib')"
      ],
      "metadata": {
        "id": "xpeDRWtpiBVP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "scaler2 = joblib.load('drive/MyDrive/IntroAi/scaler2.joblib')"
      ],
      "metadata": {
        "id": "Fy6k3mktRQNX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "encoded = scaler2.transform(Xtestdata)"
      ],
      "metadata": {
        "id": "ojEZj-C_RYXF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.predict(encoded)"
      ],
      "metadata": {
        "id": "C7AoxBkDuXHT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Finding of the confidence score of the our final model for deployment"
      ],
      "metadata": {
        "id": "i9J2P9eeWXG0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "base_model_predictions = []\n",
        "for model in voting_final.estimators_:\n",
        "    base_model_predictions.append(model.predict(finalxdata))\n",
        "\n",
        "variance_of_predictions = np.var(base_model_predictions)\n",
        "\n",
        "confidence_score = 1 - (msetestfinal / variance_of_predictions)\n",
        "\n",
        "print(\"Confidence Score:\", confidence_score)"
      ],
      "metadata": {
        "id": "T-cGXpzbWdjJ"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "private_outputs": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}